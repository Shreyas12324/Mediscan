{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54ffef16-ba0a-4a51-b446-b0029a852c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in C:/Users/shrey/OneDrive/Documents/mediscan/.git/\n"
     ]
    }
   ],
   "source": [
    "!git init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45384bfe-f991-461c-8136-7033386683de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: remote origin already exists.\n"
     ]
    }
   ],
   "source": [
    "!git remote add origin  https://github.com/Shreyas12324/Mediscan.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d327dcc-74fb-4487-9975-46c04a26e1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\thttps://github.com/Shreyas12324/Mediscan.git (fetch)\n",
      "origin\thttps://github.com/Shreyas12324/Mediscan.git (push)\n"
     ]
    }
   ],
   "source": [
    "!git remote -v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdae01c1-b6c3-43ca-aae2-080c2dcf1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git remote remove origin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd7e5bd-44e3-40a0-bd3c-9598288cf096",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git remote add origin https://github.com/Shreyas12324/Mediscan.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feec39fa-5475-4881-b653-86d113559f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\thttps://github.com/Shreyas12324/Mediscan.git (fetch)\n",
      "origin\thttps://github.com/Shreyas12324/Mediscan.git (push)\n"
     ]
    }
   ],
   "source": [
    "!git remote -v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e1ad5fe-703d-4a68-b1ed-4c08e03a7f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo __pycache__/ > .gitignore\n",
    "!echo .vscode/ >> .gitignore\n",
    "!echo *.log >> .gitignore\n",
    "!echo dataset/ >> .gitignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dccce2d-2be2-4b3e-a7e6-00feb1f61db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of '.ipynb_checkpoints/week1_setup-checkpoint.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'week1_setup.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "Author identity unknown\n",
      "\n",
      "*** Please tell me who you are.\n",
      "\n",
      "Run\n",
      "\n",
      "  git config --global user.email \"you@example.com\"\n",
      "  git config --global user.name \"Your Name\"\n",
      "\n",
      "to set your account's default identity.\n",
      "Omit --global to set the identity only in this repository.\n",
      "\n",
      "fatal: unable to auto-detect email address (got 'shrey@LAPTOP-QLE66MBU.(none)')\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"Week 1 Project Setup\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6cb05ae-c28f-486a-b480-894aea71c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global user.email \"shreyasshikshantar@gmail.com\"\n",
    "!git config --global user.name \"Shreyas12324\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "338178bc-7d4a-4f11-864f-30c98879359a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'week1_setup.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master (root-commit) e40f02a] Week 1 Project Setup\n",
      " 3 files changed, 196 insertions(+)\n",
      " create mode 100644 .gitignore\n",
      " create mode 100644 .ipynb_checkpoints/week1_setup-checkpoint.ipynb\n",
      " create mode 100644 week1_setup.ipynb\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"Week 1 Project Setup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe680d1f-b36e-44ed-8ba9-1a0fe6c1c90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch 'master' set up to track 'origin/master'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/Shreyas12324/Mediscan.git\n",
      " * [new branch]      master -> master\n"
     ]
    }
   ],
   "source": [
    "!git push -u origin master\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ce209e5-737e-4c18-97cc-559db0f08413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: src refspec main does not match any\n",
      "error: failed to push some refs to 'https://github.com/Shreyas12324/Mediscan.git'\n"
     ]
    }
   ],
   "source": [
    "!git push -u origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc0251b-eb5c-46ae-9c45-71287c7a0d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.18.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\shrey\\OneDrive\\Documents\\mediscan\\mediscan_env\\Lib\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3704781a-6349-43bd-ba6f-c79c3399beb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted to dataset/\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "zip_file_path = \"archive (1).zip\"  # Change this to your actual ZIP file name\n",
    "extract_folder = \"dataset\"  # Change this if you want a different folder name\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "\n",
    "print(f\"Extracted to {extract_folder}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395c952e-d075-4025-83d9-74dfe40735ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in dataset folder: ['.ipynb_checkpoints', 'archive (1).zip', 'dataset']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List files in the dataset folder\n",
    "dataset_path = \"dataset\"  # Change this if you extracted to a different folder\n",
    "\n",
    "print(\"Files in dataset folder:\", os.listdir(dataset_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee999fed-29e5-4537-9fba-574ed544a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==2.0.0\n",
      "  Using cached numpy-2.0.0.tar.gz (18.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [21 lines of output]\n",
      "  + C:\\Users\\shrey\\OneDrive\\Documents\\mediscan\\mediscan_env\\Scripts\\python.exe C:\\Users\\shrey\\AppData\\Local\\Temp\\pip-install-_mlb_6et\\numpy_b38f5848f3234cd3bd0da228f07d2740\\vendored-meson\\meson\\meson.py setup C:\\Users\\shrey\\AppData\\Local\\Temp\\pip-install-_mlb_6et\\numpy_b38f5848f3234cd3bd0da228f07d2740 C:\\Users\\shrey\\AppData\\Local\\Temp\\pip-install-_mlb_6et\\numpy_b38f5848f3234cd3bd0da228f07d2740\\.mesonpy-od9hfpxu -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\shrey\\AppData\\Local\\Temp\\pip-install-_mlb_6et\\numpy_b38f5848f3234cd3bd0da228f07d2740\\.mesonpy-od9hfpxu\\meson-python-native-file.ini\n",
      "  The Meson build system\n",
      "  Version: 1.2.99\n",
      "  Source dir: C:\\Users\\shrey\\AppData\\Local\\Temp\\pip-install-_mlb_6et\\numpy_b38f5848f3234cd3bd0da228f07d2740\n",
      "  Build dir: C:\\Users\\shrey\\AppData\\Local\\Temp\\pip-install-_mlb_6et\\numpy_b38f5848f3234cd3bd0da228f07d2740\\.mesonpy-od9hfpxu\n",
      "  Build type: native build\n",
      "  Project name: NumPy\n",
      "  Project version: 2.0.0\n",
      "  WARNING: Failed to activate VS environment: Could not parse vswhere.exe output\n",
      "  \n",
      "  ..\\meson.build:1:0: ERROR: Unknown compiler(s): [['icl'], ['cl'], ['cc'], ['gcc'], ['clang'], ['clang-cl'], ['pgcc']]\n",
      "  The following exception(s) were encountered:\n",
      "  Running `icl \"\"` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "  Running `cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "  Running `cc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "  Running `gcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "  Running `clang --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "  Running `clang-cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "  Running `pgcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "  \n",
      "  A full log can be found at C:\\Users\\shrey\\AppData\\Local\\Temp\\pip-install-_mlb_6et\\numpy_b38f5848f3234cd3bd0da228f07d2740\\.mesonpy-od9hfpxu\\meson-logs\\meson-log.txt\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2d371f-fa29-4a0b-b937-61ebb2810074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b86b084-0370-4ce1-83c4-8714491e7c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.2.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.2.3-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 2.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.4/12.6 MB 3.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.6/12.6 MB 3.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.9/12.6 MB 2.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.9/12.6 MB 2.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.7/12.6 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.8/12.6 MB 2.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.6/12.6 MB 2.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 3.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.7/12.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.7/12.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.3 which is incompatible.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d483afc-120d-4fec-9e0d-25e650d30fcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\shrey\\OneDrive\\Documents\\mediscan\\mediscan_env\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 70, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive\\Documents\\mediscan\\mediscan_env\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:70\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39m__version__)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\mediscan\\mediscan_env\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\mediscan\\mediscan_env\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:85\u001b[0m\n\u001b[0;32m     83\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     86\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     87\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     88\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\shrey\\OneDrive\\Documents\\mediscan\\mediscan_env\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 70, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1774a0-57c3-4f72-ad44-3d43a8015b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.18.0\n",
      "Uninstalling tensorflow-2.18.0:\n",
      "  Successfully uninstalled tensorflow-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow --yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b6f1c8-a5df-45fa-b8f8-4548a58e6dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.1\n"
     ]
    }
   ],
   "source": [
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9611c9-12ce-4fd3-a6fb-ad0b6009a3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70559f0f-a648-4ccc-a820-8fb349b4576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extracted successfully!\n",
      "Extracted files: ['.ipynb_checkpoints', 'archive (1).zip', 'dataset']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to your uploaded zip file\n",
    "zip_path = \"archive (1).zip\"  # Change if filename is different\n",
    "\n",
    "# Extract it\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"dataset\")  # Extract to a folder named 'dataset'\n",
    "\n",
    "# Verify extraction\n",
    "print(\"Dataset extracted successfully!\")\n",
    "print(\"Extracted files:\", os.listdir(\"dataset\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e59d08e-e077-479d-8970-0003d20b9ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'archive (1).zip', 'dataset']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check the dataset folder structure\n",
    "dataset_path = \"dataset\"\n",
    "print(os.listdir(dataset_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a61d47-da38-4e1a-a23d-3b2f55e8b305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files: ['.ipynb_checkpoints', 'archive (1).zip', 'dataset']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "inner_zip_path = os.path.join(dataset_path, \"archive (1).zip\")  # Inner ZIP file path\n",
    "\n",
    "# Extract it\n",
    "with zipfile.ZipFile(inner_zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(dataset_path)  # Extract inside dataset folder\n",
    "\n",
    "# Check folder structure again\n",
    "print(\"Extracted files:\", os.listdir(dataset_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12db06e-18e8-4b1f-a2c3-8bce2938f863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'archive (1).zip', 'dataset']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(dataset_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f90f84-dc7f-4715-b894-e635dabb5804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define the zip file path\n",
    "zip_path = \"dataset/archive (1).zip\"\n",
    "extract_to = \"dataset/\"\n",
    "\n",
    "# Ensure the dataset folder exists\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "\n",
    "print(\"Extraction complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da3eea8-db34-4252-9403-36f4e86ee9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3930d6b8-d084-486c-8e98-2c9509161fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'archive (1).zip', 'dataset']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(extract_to))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b0c72b6-be70-4da5-87da-b6fcaee301a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Moving: ['cataract', 'diabetic_retinopathy', 'glaucoma', 'normal']\n",
      "After Moving: ['.ipynb_checkpoints', 'archive (1).zip', 'cataract', 'dataset', 'diabetic_retinopathy', 'glaucoma', 'normal']\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "base_path = \"archive (1)/dataset\"\n",
    "destination_path = \"dataset\"\n",
    "\n",
    "# List the contents of the extracted dataset\n",
    "print(\"Before Moving:\", os.listdir(base_path))\n",
    "\n",
    "# Move each class folder from extracted dataset to main dataset directory\n",
    "for folder in os.listdir(base_path):\n",
    "    shutil.move(os.path.join(base_path, folder), destination_path)\n",
    "\n",
    "# Verify the move\n",
    "print(\"After Moving:\", os.listdir(destination_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce77829e-c0ae-485d-bc30-41f4a10b2735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"dataset/archive (1)\", ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74834f0-f0dd-4c2a-be9a-24a4f6f70301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
